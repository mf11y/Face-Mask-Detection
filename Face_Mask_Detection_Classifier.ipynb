{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2966 images belonging to 2 classes.\n",
      "Found 742 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "img_rows, img_cols = 50,50\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = './Data/train/'\n",
    "validation_data_dir = './Data/val/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  rotation_range = 40,\n",
    "                                  width_shift_range = .3,\n",
    "                                  height_shift_range = .3,\n",
    "                                  shear_range = .2,\n",
    "                                  zoom_range = .2,\n",
    "                                  horizontal_flip = True,\n",
    "                                  fill_mode = 'nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                   target_size=(img_rows, img_cols),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = 'binary',\n",
    "                                                   shuffle = True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                              target_size = (img_rows, img_cols),\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               4333696   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,354,113\n",
      "Trainable params: 4,353,665\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD\n",
    "\n",
    "input_shape = (50,50,3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(3,3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,\n",
    "                 (3,3),\n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint('./Model/mask_detection_model.h5',\n",
    "                             monitor = 'val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss',\n",
    "                         min_delta= 0,\n",
    "                         patience = 20,\n",
    "                         verbose=1,\n",
    "                         restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                             factor=.2,\n",
    "                             patience=5,\n",
    "                             verbose = 1,\n",
    "                             min_delta = .0001)\n",
    "\n",
    "callbacks = [earlystop, reduce_lr, checkpoint]\n",
    "\n",
    "\n",
    "no_train = 2966\n",
    "no_val = 742\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "185/185 [==============================] - 62s 323ms/step - loss: 0.4149 - accuracy: 0.8542 - val_loss: 0.5407 - val_accuracy: 0.6413\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.54066, saving model to ./Model\\mask_detection_model.h5\n",
      "Epoch 2/100\n",
      "185/185 [==============================] - 52s 281ms/step - loss: 0.2867 - accuracy: 0.8822 - val_loss: 0.2036 - val_accuracy: 0.9321\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54066 to 0.20361, saving model to ./Model\\mask_detection_model.h5\n",
      "Epoch 3/100\n",
      "185/185 [==============================] - 44s 240ms/step - loss: 0.2667 - accuracy: 0.8982 - val_loss: 0.1635 - val_accuracy: 0.9497\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20361 to 0.16354, saving model to ./Model\\mask_detection_model.h5\n",
      "Epoch 4/100\n",
      "185/185 [==============================] - 46s 251ms/step - loss: 0.2364 - accuracy: 0.9106 - val_loss: 0.0795 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.16354 to 0.07950, saving model to ./Model\\mask_detection_model.h5\n",
      "Epoch 5/100\n",
      "185/185 [==============================] - 60s 326ms/step - loss: 0.2128 - accuracy: 0.9257 - val_loss: 0.1416 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07950\n",
      "Epoch 6/100\n",
      "185/185 [==============================] - 61s 328ms/step - loss: 0.2447 - accuracy: 0.9061 - val_loss: 0.2280 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07950\n",
      "Epoch 7/100\n",
      "185/185 [==============================] - 48s 259ms/step - loss: 0.2070 - accuracy: 0.9170 - val_loss: 0.0918 - val_accuracy: 0.9715\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07950\n",
      "Epoch 8/100\n",
      "185/185 [==============================] - 47s 255ms/step - loss: 0.2193 - accuracy: 0.9146 - val_loss: 0.1785 - val_accuracy: 0.9470\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07950\n",
      "Epoch 9/100\n",
      "185/185 [==============================] - 42s 229ms/step - loss: 0.1937 - accuracy: 0.9300 - val_loss: 0.0660 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.07950 to 0.06604, saving model to ./Model\\mask_detection_model.h5\n",
      "Epoch 10/100\n",
      "185/185 [==============================] - 48s 259ms/step - loss: 0.1938 - accuracy: 0.9360 - val_loss: 0.0628 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.06604 to 0.06283, saving model to ./Model\\mask_detection_model.h5\n",
      "Epoch 11/100\n",
      "185/185 [==============================] - 44s 237ms/step - loss: 0.1793 - accuracy: 0.9318 - val_loss: 0.1322 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06283\n",
      "Epoch 12/100\n",
      "185/185 [==============================] - 45s 243ms/step - loss: 0.1915 - accuracy: 0.9286 - val_loss: 0.1146 - val_accuracy: 0.9633\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06283\n",
      "Epoch 13/100\n",
      "185/185 [==============================] - 46s 251ms/step - loss: 0.1994 - accuracy: 0.9163 - val_loss: 1.0612 - val_accuracy: 0.6698\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06283\n",
      "Epoch 14/100\n",
      "185/185 [==============================] - 43s 235ms/step - loss: 0.1775 - accuracy: 0.9329 - val_loss: 0.0707 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06283\n",
      "Epoch 15/100\n",
      "185/185 [==============================] - 52s 280ms/step - loss: 0.1745 - accuracy: 0.9317 - val_loss: 0.1006 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06283\n",
      "Epoch 16/100\n",
      "185/185 [==============================] - 57s 308ms/step - loss: 0.1735 - accuracy: 0.9415 - val_loss: 0.0822 - val_accuracy: 0.9728\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06283\n",
      "Epoch 17/100\n",
      "185/185 [==============================] - 53s 286ms/step - loss: 0.1636 - accuracy: 0.9392 - val_loss: 0.0684 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06283\n",
      "Epoch 18/100\n",
      "185/185 [==============================] - 47s 256ms/step - loss: 0.1592 - accuracy: 0.9416 - val_loss: 0.0672 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06283\n",
      "Epoch 19/100\n",
      "185/185 [==============================] - 50s 268ms/step - loss: 0.1551 - accuracy: 0.9421 - val_loss: 0.0585 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.06283 to 0.05854, saving model to ./Model\\mask_detection_model.h5\n",
      "Epoch 20/100\n",
      "185/185 [==============================] - 51s 274ms/step - loss: 0.1600 - accuracy: 0.9326 - val_loss: 0.0582 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.05854 to 0.05824, saving model to ./Model\\mask_detection_model.h5\n",
      "Epoch 21/100\n",
      "185/185 [==============================] - 52s 282ms/step - loss: 0.1316 - accuracy: 0.9483 - val_loss: 0.0769 - val_accuracy: 0.9742\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.05824\n",
      "Epoch 22/100\n",
      "185/185 [==============================] - 53s 288ms/step - loss: 0.1137 - accuracy: 0.9607 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.05824 to 0.05408, saving model to ./Model\\mask_detection_model.h5\n",
      "Epoch 23/100\n",
      "185/185 [==============================] - 52s 284ms/step - loss: 0.1607 - accuracy: 0.9404 - val_loss: 0.0518 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.05408 to 0.05184, saving model to ./Model\\mask_detection_model.h5\n",
      "Epoch 24/100\n",
      "185/185 [==============================] - 52s 282ms/step - loss: 0.1454 - accuracy: 0.9508 - val_loss: 0.0609 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.05184\n",
      "Epoch 25/100\n",
      "185/185 [==============================] - 53s 288ms/step - loss: 0.1352 - accuracy: 0.9486 - val_loss: 0.0526 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05184\n",
      "Epoch 26/100\n",
      "185/185 [==============================] - 54s 291ms/step - loss: 0.1467 - accuracy: 0.9431 - val_loss: 0.0750 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.05184\n",
      "Epoch 27/100\n",
      "185/185 [==============================] - 42s 225ms/step - loss: 0.1572 - accuracy: 0.9393 - val_loss: 0.1141 - val_accuracy: 0.9647\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.05184\n",
      "Epoch 28/100\n",
      "185/185 [==============================] - 34s 181ms/step - loss: 0.1454 - accuracy: 0.9426 - val_loss: 0.0615 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05184\n",
      "Epoch 29/100\n",
      "185/185 [==============================] - 48s 259ms/step - loss: 0.1242 - accuracy: 0.9528 - val_loss: 0.0544 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05184\n",
      "Epoch 30/100\n",
      "185/185 [==============================] - 52s 280ms/step - loss: 0.1715 - accuracy: 0.9362 - val_loss: 0.0555 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05184\n",
      "Epoch 31/100\n",
      "185/185 [==============================] - 56s 300ms/step - loss: 0.1262 - accuracy: 0.9499 - val_loss: 0.0522 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.05184\n",
      "Epoch 32/100\n",
      "185/185 [==============================] - 53s 284ms/step - loss: 0.1508 - accuracy: 0.9423 - val_loss: 0.0540 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.05184\n",
      "Epoch 33/100\n",
      "185/185 [==============================] - 53s 284ms/step - loss: 0.1449 - accuracy: 0.9452 - val_loss: 0.0528 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05184\n",
      "Epoch 34/100\n",
      "185/185 [==============================] - 51s 275ms/step - loss: 0.1216 - accuracy: 0.9549 - val_loss: 0.0529 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05184\n",
      "Epoch 35/100\n",
      "185/185 [==============================] - 50s 270ms/step - loss: 0.1068 - accuracy: 0.9643 - val_loss: 0.0534 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.05184\n",
      "Epoch 36/100\n",
      "185/185 [==============================] - 50s 270ms/step - loss: 0.1458 - accuracy: 0.9445 - val_loss: 0.0527 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.05184\n",
      "Epoch 37/100\n",
      "185/185 [==============================] - 51s 274ms/step - loss: 0.1123 - accuracy: 0.9632 - val_loss: 0.0533 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.05184\n",
      "Epoch 38/100\n",
      "185/185 [==============================] - 50s 269ms/step - loss: 0.1160 - accuracy: 0.9552 - val_loss: 0.0528 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05184\n",
      "Epoch 39/100\n",
      "185/185 [==============================] - 50s 271ms/step - loss: 0.1105 - accuracy: 0.9635 - val_loss: 0.0529 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05184\n",
      "Epoch 40/100\n",
      "185/185 [==============================] - 51s 275ms/step - loss: 0.1292 - accuracy: 0.9511 - val_loss: 0.0532 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05184\n",
      "Epoch 41/100\n",
      "185/185 [==============================] - 51s 276ms/step - loss: 0.1188 - accuracy: 0.9523 - val_loss: 0.0530 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05184\n",
      "Epoch 42/100\n",
      "185/185 [==============================] - 51s 274ms/step - loss: 0.1384 - accuracy: 0.9443 - val_loss: 0.0532 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05184\n",
      "Epoch 43/100\n",
      "185/185 [==============================] - 53s 288ms/step - loss: 0.1233 - accuracy: 0.9546 - val_loss: 0.0530 - val_accuracy: 0.9796\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05184\n",
      "Epoch 00043: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch = no_train // batch_size,\n",
    "                    epochs  = epochs,\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps=no_val // batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
